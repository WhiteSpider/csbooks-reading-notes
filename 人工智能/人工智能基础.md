# AI基础
## 参考内容
[1] 极客时间：《人工智能基础》, 王天一

## 1. 机器学习概论
简单来说，**机器学习就是从大量现象中提取反复出现的规律和模式**。
ML是计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的学科。 

**基本概念**
* 属性：对对象某些性质的描述
* 属性值：属性的取值
* 数据：不同属性值有序排列得到的向量，也叫做**实例**
* 根据线性代数知识，数据的不同属性可以视为相互独立，所以每个属性代表一个不同的维度，这些维度共同张成了**特征空间**
* 每个实例就是特征空间中的一个点，即**特征向量**， 这和线性代数中的特征向量和特征值概念不同。
* 误差：ML的实际预测输出与样本真实输出之间的差异，在分类中，常用的误差函数是**错误率**，误差可以进一步分为训练误差和测试误差。
* 训练误差：学习器在训练数据集上的误差，又称为经验误差
* 测试误差：学习器在新样本上的误差，又称为泛化误差。
* 过拟合：训练误差小，泛化误差大。
* 欠拟合：训练数据的基本性质都没有学到。
* 欠拟合可以通过改进学习器的算法克服，过拟合无法避免。
* 整体而言，**测试误差与模型复杂度之间呈现抛物线关系**，当模型复杂度较低时，测试误差较高；随着模型复杂度的增加，测试误差将逐渐下降并达到最小值；之后，当模型复杂度继续上升时，测试误差随之增加，对应着过拟合的发生。
* 在模型选择中，一种广泛使用的方法时交叉验证
* 除了算法本身，参数的取值也是影响模型性能的重要因素。因此，调参，也就是对算法参数的设定，时ML中重要的工程问题，这点在神经网络与深度学习中非常重要。
  * 举例：假如一个ANN（人工神经网络）包含1000个参数，每个参数有10中取值的可能，对于每一组训练/测试集就有$1000^{10}$个模型需要考察。因此，在调参过程中，一个主要的问题就是性能和效率的折中。

**ML预测问题的分类**
* **分类问题**：输出变量为有限个离散变量，当个数为2，即为简单的二分类问题
* **回归问题**：输入变量和输出变量均为连续变量
* **标注问题**：输入变量和输出变量均为变量序列

**ML学习的分类**
* **监督学习**：基于已知类别的训练数据进行学习
* **无监督学习**：基于未知类别的训练数据进行学习
* **半监督学习**：同时使用已知类比和未知类别的训练数据进行学习。
* 一般而言，效果较好的学习算法执行的都是监督学习的学习任务，号称自学成才的AlphaGo Zero, 其训练过程也要受到围棋规则的限制，也脱不开监督学习的范畴。

**监督学习**
* 假定训练数据满足独立同分布条件，并根据训练数据学习出一个由输入到输出的映射模型。
* 反映这种关系的模型可能有无数种，所有模型共同组成了假设空间。
* 监督学习的任务就是在假设空间中根据特定的误差准则寻找最优的模型
* 根据学习方法不同，可以分为：
  * 生成方法类别：根据输入数据和输出数据之间的联合概率确定条件概率$P(Y|X)$,这种方法表示了输入$X$和输出$Y$之间的生成关系。
  * 判别方法类别：直接学习条件概率分布$P(Y|X)$或者决策函数$f(X)$, 这种方法表示了根据输入$X$得出输出$Y$的预测方法。
  * 生成方法具有更快的收敛速度和更广的应用范围，判别方法具有更高的准确度和更简单的使用方法。

**知识要点**
* ML是计算机基于数据构建概率统计模型并运用模型对数据进行预测和分析的学科
* 根据输入输出类型不同，ML可以分为分类问题、回归问题、标注问题。
* 过拟合是ML中不可避免的问题
* 监督学习是目前ML中的主流，包括：生产方法和判别方法

## 2. 线性回归




